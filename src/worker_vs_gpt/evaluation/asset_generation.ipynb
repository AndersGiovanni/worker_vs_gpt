{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate plots for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "datasets = [f_ for f_ in os.listdir(\"results/\") if f_ != \".DS_Store\"]\n",
    "\n",
    "dataset_to_figure_size = {\n",
    "    \"hayati_politeness\": (20, 6),\n",
    "    \"empathy#empathy_bin\": (20, 6),\n",
    "    \"hypo-l\": (20, 6),\n",
    "    \"questionintimacy\": (20, 20),\n",
    "    \"talkdown-pairs\": (20, 6),\n",
    "    \"crowdflower\": (20, 20),\n",
    "    \"ten-dim\": (20, 20),\n",
    "    \"sentiment\": (20, 6),\n",
    "    \"same-side-pairs\": (20, 6),\n",
    "    \"hate-speech\": (20, 6),\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        results = json.load(open(f\"results/{dataset}/llama-2-70b_similarity.json\"))\n",
    "        results_gpt = json.load(open(f\"results/{dataset}/similarity.json\"))\n",
    "    else:\n",
    "        results_gpt = json.load(open(f\"results/{dataset}/gpt-4_similarity.json\"))\n",
    "    length = len(results)\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        targets = set([result[\"target\"] for result in results])\n",
    "    else:\n",
    "        targets = set([result[\"target\"] for result in results_gpt])\n",
    "\n",
    "    metrics_llama = {\n",
    "        target: {\n",
    "            \"bleu_score\": [],\n",
    "            \"rouge_score\": [],\n",
    "            \"Llama cosine\": [],\n",
    "            # \"spacy_cosine_similarity\": [],\n",
    "            \"percentage_token_overlap\": [],\n",
    "            \"percentage_token_overlap\": [],\n",
    "        }\n",
    "        for target in targets\n",
    "    }\n",
    "    metrics_gpt = {\n",
    "        target: {\n",
    "            \"bleu_score\": [],\n",
    "            \"rouge_score\": [],\n",
    "            \"GPT cosine\": [],\n",
    "            # \"spacy_cosine_similarity\": [],\n",
    "            \"percentage_token_overlap\": [],\n",
    "            \"percentage_token_overlap\": [],\n",
    "        }\n",
    "        for target in targets\n",
    "    }\n",
    "\n",
    "    bleu = []\n",
    "    rouge = []\n",
    "    transformer_similarity_llama = []\n",
    "    transformer_similarity_gpt = []\n",
    "    # spacy_similarity = []\n",
    "    token_overlap = []\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        for idx, result in enumerate(results):\n",
    "            metrics_llama[result[\"target\"]][\"bleu_score\"].append(result[\"metrics\"][\"bleu_score\"])\n",
    "            metrics_llama[result[\"target\"]][\"rouge_score\"].append(\n",
    "                result[\"metrics\"][\"rouge_score\"]\n",
    "            )\n",
    "            metrics_llama[result[\"target\"]][\"Llama cosine\"].append(\n",
    "                result[\"metrics\"][\"transformer_similarity\"]\n",
    "            )\n",
    "            metrics_llama[result[\"target\"]][\"percentage_token_overlap\"].append(\n",
    "                result[\"metrics\"][\"vocab_overlap\"][\"percentage_token_overlap\"]\n",
    "            )\n",
    "    \n",
    "    for idx, result in enumerate(results_gpt):\n",
    "        metrics_gpt[result[\"target\"]][\"bleu_score\"].append(result[\"metrics\"][\"bleu_score\"])\n",
    "        metrics_gpt[result[\"target\"]][\"rouge_score\"].append(\n",
    "            result[\"metrics\"][\"rouge_score\"]\n",
    "        )\n",
    "        metrics_gpt[result[\"target\"]][\"GPT cosine\"].append(\n",
    "            result[\"metrics\"][\"transformer_similarity\"]\n",
    "        )\n",
    "        metrics_gpt[result[\"target\"]][\"percentage_token_overlap\"].append(\n",
    "            result[\"metrics\"][\"vocab_overlap\"][\"percentage_token_overlap\"]\n",
    "        )\n",
    "\n",
    "    fig, ax = plt.subplots(len(targets), 4, figsize=dataset_to_figure_size[dataset])\n",
    "    fig.suptitle(f\"Dataset: {dataset} - length: {length}\")\n",
    "\n",
    "\n",
    "    for idx, target in enumerate(targets):\n",
    "        # Add title for entire row\n",
    "        ax[idx][0].set_title(f\"Target: {target}\")\n",
    "\n",
    "        bleu = metrics_llama[target][\"bleu_score\"]\n",
    "        bleu_gpt = metrics_gpt[target][\"bleu_score\"]\n",
    "        rouge = metrics_llama[target][\"rouge_score\"]\n",
    "        rouge_gpt = metrics_gpt[target][\"rouge_score\"]\n",
    "        transformer_similarity_llama = metrics_llama[target][\"Llama cosine\"]\n",
    "        transformer_similarity_gpt = metrics_gpt[target][\"GPT cosine\"]\n",
    "        # spacy_similarity = metrics[target][\"spacy_cosine_similarity\"]\n",
    "        token_overlap = metrics_llama[target][\"percentage_token_overlap\"]\n",
    "        token_overlap_gpt = metrics_gpt[target][\"percentage_token_overlap\"]\n",
    "\n",
    "        sns.histplot(bleu, ax=ax[idx][0], color=\"blue\", label=\"BLEU Llama\", kde=True)\n",
    "        sns.histplot(bleu_gpt, ax=ax[idx][0], color=\"red\", label=\"BLEU GPT-4\", kde=True)\n",
    "        \n",
    "        sns.histplot(rouge, ax=ax[idx][1], color=\"blue\", label=\"rouge Llama\", kde=True)\n",
    "        sns.histplot(rouge_gpt, ax=ax[idx][1], color=\"red\", label=\"rouge GPT-4\", kde=True)\n",
    "\n",
    "        sns.histplot(\n",
    "            transformer_similarity_llama,\n",
    "            ax=ax[idx][2],\n",
    "            label=\"Llama cosine\",\n",
    "            color = \"blue\",\n",
    "            kde=True,\n",
    "        )\n",
    "        sns.histplot(\n",
    "            transformer_similarity_gpt,\n",
    "            ax=ax[idx][2],\n",
    "            label=\"GPT-4 cosine\",\n",
    "            color = \"red\",\n",
    "            kde=True,\n",
    "        )\n",
    "        # sns.histplot(\n",
    "        #     spacy_similarity, ax=ax[idx][1], label=\"spacy_similarity\", kde=True\n",
    "        # )\n",
    "\n",
    "        sns.histplot(token_overlap, ax=ax[idx][3], label=\"Token overlap Llama\", kde=True, color = \"blue\")\n",
    "        sns.histplot(token_overlap_gpt, ax=ax[idx][3], label=\"Token overlap GPT-4\", kde=True, color = \"red\")\n",
    "\n",
    "        ax[idx][0].legend()\n",
    "        ax[idx][1].legend()\n",
    "        ax[idx][2].legend()\n",
    "        ax[idx][3].legend()\n",
    "\n",
    "        # x-axis should be 0 to 1\n",
    "        ax[idx][0].set_xlim(0, 1)\n",
    "        ax[idx][1].set_xlim(0, 1)\n",
    "        ax[idx][2].set_xlim(0, 1)\n",
    "        ax[idx][3].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"assets/{dataset}-histogram-combined.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from utils import assert_path\n",
    "from utils import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name: str = \"hayati_politeness\"\n",
    "assert_path(f\"assets/{dataset_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacey similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the data\n",
    "filename: str = f\"results/{dataset_name}/spacy_similarity.json\"\n",
    "data: Dict = load_json(filename)\n",
    "\n",
    "# Create distribution plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, target in enumerate(data):\n",
    "    values: List[float] = data[target]\n",
    "\n",
    "    sns.histplot(values, kde=True, ax=ax[i])\n",
    "    mean_polite = np.mean(values)\n",
    "    median_polite = np.median(values)\n",
    "    ax[i].axvline(\n",
    "        mean_polite, color=\"red\", linestyle=\"--\", label=f\"Mean: {mean_polite:.2f}\"\n",
    "    )\n",
    "    ax[i].axvline(\n",
    "        median_polite,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Median: {median_polite:.2f}\",\n",
    "    )\n",
    "    ax[i].set_title(target)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"Cosine Similarity\")\n",
    "\n",
    "# add overall title\n",
    "fig.suptitle(f\"Distribution of Spacy Similarity Scores for {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"assets/{dataset_name}/spacy_similarity_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename: str = f\"results/{dataset_name}/vocab_overlap.json\"\n",
    "data: Dict = load_json(filename)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for i, target in enumerate(data):\n",
    "    percentages = [entry[\"percentage_token_overlap\"] for entry in data[target]]\n",
    "\n",
    "    sns.histplot(percentages, kde=True, ax=ax[i])\n",
    "    mean = np.mean(percentages)\n",
    "    median = np.median(percentages)\n",
    "\n",
    "    ax[i].axvline(mean, color=\"red\", linestyle=\"--\", label=f\"Mean: {mean:.2f}\")\n",
    "    ax[i].axvline(\n",
    "        median,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Median: {median:.2f}\",\n",
    "    )\n",
    "    ax[i].set_title(target)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"Percentage Token Overlap\")\n",
    "\n",
    "# add overall title\n",
    "fig.suptitle(f\"Distribution of Vocab Overlap for {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"assets/{dataset_name}/vocab_overlap_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU and ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_json(f\"results/{dataset_name}/rouge.json\")\n",
    "bleu = load_json(f\"results/{dataset_name}/bleu.json\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, target in enumerate(rouge):\n",
    "    bleu_score: List[float] = bleu[target]\n",
    "    rouge_score: List[float] = rouge[target]\n",
    "\n",
    "    sns.histplot(bleu_score, kde=True, ax=ax[i], label=\"BLEU\")\n",
    "    sns.histplot(rouge_score, kde=True, ax=ax[i], label=\"ROUGE\")\n",
    "\n",
    "    ax[i].set_title(target)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(\"Score\")\n",
    "\n",
    "fig.suptitle(f\"Distribution of BLEU and ROUGE for {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"assets/{dataset_name}/bleu_rouge_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined diversity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "datasets = [f_ for f_ in os.listdir(\"results/\") if f_ != \".DS_Store\"]\n",
    "\n",
    "dataset_to_figure_size = {\n",
    "    \"hayati_politeness\": (10, 5),\n",
    "    \"empathy#empathy_bin\": (10,5),\n",
    "    \"hypo-l\": (10,5),\n",
    "    \"questionintimacy\": (10,5),\n",
    "    \"talkdown-pairs\": (10,5),\n",
    "    \"crowdflower\": (10,5),\n",
    "    \"ten-dim\": (10,5),\n",
    "    \"sentiment\": (10,5),\n",
    "    \"same-side-pairs\": (10,5),\n",
    "    \"hate-speech\": (10,5),\n",
    "}\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        results = json.load(open(f\"results/{dataset}/llama-2-70b_similarity.json\"))\n",
    "        results_gpt = json.load(open(f\"results/{dataset}/similarity.json\"))\n",
    "    else:\n",
    "        results_gpt = json.load(open(f\"results/{dataset}/gpt-4_similarity.json\"))\n",
    "    length = len(results)\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        targets = set([result[\"target\"] for result in results])\n",
    "    else:\n",
    "        targets = set([result[\"target\"] for result in results_gpt])\n",
    "\n",
    "    metrics_llama ={\n",
    "            \"Llama cosine\": [],\n",
    "            \"percentage_token_overlap\": [],\n",
    "        }\n",
    "    metrics_gpt = {\n",
    "            \"GPT cosine\": [],\n",
    "            \"percentage_token_overlap\": [], \n",
    "        }\n",
    "    \n",
    "    transformer_similarity_llama = []\n",
    "    transformer_similarity_gpt = []\n",
    "    token_overlap = []\n",
    "\n",
    "    if dataset != \"hate-speech\":\n",
    "        for idx, result in enumerate(results):\n",
    "            metrics_llama[\"Llama cosine\"].append(\n",
    "                result[\"metrics\"][\"transformer_similarity\"]\n",
    "            )\n",
    "            metrics_llama[\"percentage_token_overlap\"].append(\n",
    "                result[\"metrics\"][\"vocab_overlap\"][\"percentage_token_overlap\"]\n",
    "            )\n",
    "    \n",
    "    for idx, result in enumerate(results_gpt):\n",
    "        metrics_gpt[\"GPT cosine\"].append(\n",
    "            result[\"metrics\"][\"transformer_similarity\"]\n",
    "        )\n",
    "        metrics_gpt[\"percentage_token_overlap\"].append(\n",
    "            result[\"metrics\"][\"vocab_overlap\"][\"percentage_token_overlap\"]\n",
    "        )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=dataset_to_figure_size[dataset])\n",
    "    fig.suptitle(f\"Dataset: {dataset} - length: {length}\")\n",
    "\n",
    "        # Add title for entire row\n",
    "    # ax[0].set_title(f\"Target: {target}\")\n",
    "\n",
    "    transformer_similarity_llama = metrics_llama[\"Llama cosine\"]\n",
    "    transformer_similarity_gpt = metrics_gpt[\"GPT cosine\"]\n",
    "    # spacy_similarity = metrics[\"spacy_cosine_similarity\"]\n",
    "    token_overlap = metrics_llama[\"percentage_token_overlap\"]\n",
    "    token_overlap_gpt = metrics_gpt[\"percentage_token_overlap\"]\n",
    "\n",
    "    sns.kdeplot(\n",
    "        transformer_similarity_llama,\n",
    "        ax=ax[0],\n",
    "        label=\"Llama cosine\",\n",
    "        color = \"blue\",\n",
    "        fill=True\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        transformer_similarity_gpt,\n",
    "        ax=ax[0],\n",
    "        label=\"GPT-4 cosine\",\n",
    "        color = \"red\",\n",
    "        fill=True\n",
    "    )\n",
    "    # sns.kdeplot(\n",
    "    #     spacy_similarity, ax=ax[1], label=\"spacy_similarity\", kde=True\n",
    "    # )\n",
    "\n",
    "    sns.kdeplot(token_overlap, ax=ax[1], label=\"Token overlap Llama\", color = \"blue\", fill=True)\n",
    "    sns.kdeplot(token_overlap_gpt, ax=ax[1], label=\"Token overlap GPT-4\", color = \"red\", fill=True)\n",
    "\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "\n",
    "    # x-axis should be 0 to 1\n",
    "    ax[0].set_xlim(0, 1)\n",
    "    ax[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(f\"assets/{dataset}-histogram-combined-aggregate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parrots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
